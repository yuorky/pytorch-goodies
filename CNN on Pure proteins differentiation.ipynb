{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import SubsetRandomSampler as SRS \n",
    "from torch.utils.data import DataLoader\n",
    "from data.Dataset import Proteins\n",
    "from models import resnet101\n",
    "from sklearn.model_selection import train_test_split\n",
    "from config import DefaultConfig\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = DefaultConfig()\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "])\n",
    "\n",
    "all_dataset = Proteins(root=opt.root, transforms=transform)\n",
    "\n",
    "# split training and test set 7:3\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(all_dataset.labels)),\n",
    "    test_size=0.3,\n",
    "    stratify=all_dataset.labels\n",
    ")\n",
    "\n",
    "train_sampler = SRS(train_idx)\n",
    "test_sampler = SRS(test_idx)\n",
    "train_loader = DataLoader(all_dataset, batch_size=10, sampler=train_sampler)\n",
    "test_loader = DataLoader(all_dataset, batch_size=10, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, train_loader=train_loader):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)  # 1 is the dimension\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Decay learning rate\n",
    "\n",
    "        epoch_loss = running_loss / train_loader.sampler.indices.shape[0]\n",
    "        epoch_acc = running_corrects.item() / train_loader.sampler.indices.shape[0]\n",
    "\n",
    "        print('{} Loss: {: .4f} Acc: {: .4f}'.format(\n",
    "            'Train', epoch_loss, epoch_acc\n",
    "        ))\n",
    "        scheduler.step()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60\n",
    "    ))\n",
    "\n",
    "    # load best model weights\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader=test_loader):\n",
    "    test_corrects = 0\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)  # 1 is the dimension\n",
    "\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = test_corrects.double() / test_loader.sampler.indices.shape[0]\n",
    "\n",
    "    return test_corrects, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029\n",
      "----------\n",
      "Train Loss:  2.5297 Acc:  0.5275\n",
      "Epoch 129\n",
      "----------\n",
      "Train Loss:  1.6457 Acc:  0.4908\n",
      "Epoch 229\n",
      "----------\n",
      "Train Loss:  0.8686 Acc:  0.4908\n",
      "Epoch 329\n",
      "----------\n",
      "Train Loss:  0.7080 Acc:  0.5505\n",
      "Epoch 429\n",
      "----------\n",
      "Train Loss:  0.7082 Acc:  0.5550\n",
      "Epoch 529\n",
      "----------\n",
      "Train Loss:  0.7113 Acc:  0.5321\n",
      "Epoch 629\n",
      "----------\n",
      "Train Loss:  0.6819 Acc:  0.5321\n",
      "Epoch 729\n",
      "----------\n",
      "Train Loss:  0.6791 Acc:  0.5826\n",
      "Epoch 829\n",
      "----------\n",
      "Train Loss:  0.6937 Acc:  0.5642\n",
      "Epoch 929\n",
      "----------\n",
      "Train Loss:  0.6850 Acc:  0.5688\n",
      "Epoch 1029\n",
      "----------\n",
      "Train Loss:  0.6745 Acc:  0.5734\n",
      "Epoch 1129\n",
      "----------\n",
      "Train Loss:  0.6722 Acc:  0.5505\n",
      "Epoch 1229\n",
      "----------\n",
      "Train Loss:  0.6649 Acc:  0.5459\n",
      "Epoch 1329\n",
      "----------\n",
      "Train Loss:  0.6721 Acc:  0.5596\n",
      "Epoch 1429\n",
      "----------\n",
      "Train Loss:  0.6625 Acc:  0.5917\n",
      "Epoch 1529\n",
      "----------\n",
      "Train Loss:  0.6751 Acc:  0.5505\n",
      "Epoch 1629\n",
      "----------\n",
      "Train Loss:  0.6645 Acc:  0.5780\n",
      "Epoch 1729\n",
      "----------\n",
      "Train Loss:  0.6674 Acc:  0.5642\n",
      "Epoch 1829\n",
      "----------\n",
      "Train Loss:  0.6590 Acc:  0.6239\n",
      "Epoch 1929\n",
      "----------\n",
      "Train Loss:  0.6644 Acc:  0.5505\n",
      "Epoch 2029\n",
      "----------\n",
      "Train Loss:  0.6530 Acc:  0.6376\n",
      "Epoch 2129\n",
      "----------\n",
      "Train Loss:  0.6565 Acc:  0.6193\n",
      "Epoch 2229\n",
      "----------\n",
      "Train Loss:  0.6679 Acc:  0.5688\n",
      "Epoch 2329\n",
      "----------\n",
      "Train Loss:  0.6580 Acc:  0.5734\n",
      "Epoch 2429\n",
      "----------\n",
      "Train Loss:  0.6563 Acc:  0.5917\n",
      "Epoch 2529\n",
      "----------\n",
      "Train Loss:  0.6588 Acc:  0.6147\n",
      "Epoch 2629\n",
      "----------\n",
      "Train Loss:  0.6696 Acc:  0.5642\n",
      "Epoch 2729\n",
      "----------\n",
      "Train Loss:  0.6564 Acc:  0.5963\n",
      "Epoch 2829\n",
      "----------\n",
      "Train Loss:  0.6588 Acc:  0.5734\n",
      "Epoch 2929\n",
      "----------\n",
      "Train Loss:  0.6509 Acc:  0.6055\n",
      "Training complete in 6m 35s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer_AB40_SYN,\n",
    "                                step_size=1, gamma=0.8)\n",
    "\n",
    "scheduler_2 = ReduceLROnPlateau(optimizer_AB40_SYN, mode='max', factor=0.5,\n",
    "                                patience=1, verbose=True)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN, scheduler,\n",
    "                                 num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(scheduler.last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2379400392853824e-05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029\n",
      "----------\n",
      "Train Loss:  1.5226 Acc:  0.4771\n",
      "Epoch 129\n",
      "----------\n",
      "Train Loss:  1.0241 Acc:  0.5000\n",
      "Epoch 229\n",
      "----------\n",
      "Train Loss:  0.9459 Acc:  0.5596\n",
      "Epoch 329\n",
      "----------\n",
      "Train Loss:  0.7949 Acc:  0.5459\n",
      "Epoch 429\n",
      "----------\n",
      "Train Loss:  0.7848 Acc:  0.5183\n",
      "Epoch 529\n",
      "----------\n",
      "Train Loss:  0.7076 Acc:  0.6009\n",
      "Epoch 629\n",
      "----------\n",
      "Train Loss:  0.7236 Acc:  0.5229\n",
      "Epoch 729\n",
      "----------\n",
      "Train Loss:  0.7045 Acc:  0.4954\n",
      "Epoch 829\n",
      "----------\n",
      "Train Loss:  0.6270 Acc:  0.6193\n",
      "Epoch 929\n",
      "----------\n",
      "Train Loss:  0.7204 Acc:  0.6055\n",
      "Epoch 1029\n",
      "----------\n",
      "Train Loss:  0.6324 Acc:  0.6376\n",
      "Epoch 1129\n",
      "----------\n",
      "Train Loss:  0.6475 Acc:  0.5734\n",
      "Epoch 1229\n",
      "----------\n",
      "Train Loss:  0.5841 Acc:  0.6697\n",
      "Epoch 1329\n",
      "----------\n",
      "Train Loss:  0.5977 Acc:  0.6972\n",
      "Epoch 1429\n",
      "----------\n",
      "Train Loss:  0.4942 Acc:  0.7615\n",
      "Epoch 1529\n",
      "----------\n",
      "Train Loss:  0.4883 Acc:  0.7890\n",
      "Epoch 1629\n",
      "----------\n",
      "Train Loss:  0.5273 Acc:  0.7523\n",
      "Epoch 1729\n",
      "----------\n",
      "Train Loss:  0.3617 Acc:  0.8853\n",
      "Epoch 1829\n",
      "----------\n",
      "Train Loss:  0.4731 Acc:  0.7661\n",
      "Epoch 1929\n",
      "----------\n",
      "Train Loss:  0.5234 Acc:  0.7661\n",
      "Epoch 2029\n",
      "----------\n",
      "Train Loss:  0.5978 Acc:  0.7018\n",
      "Epoch 2129\n",
      "----------\n",
      "Train Loss:  0.5588 Acc:  0.7156\n",
      "Epoch 2229\n",
      "----------\n",
      "Train Loss:  0.4074 Acc:  0.8211\n",
      "Epoch 2329\n",
      "----------\n",
      "Train Loss:  0.3262 Acc:  0.8945\n",
      "Epoch 2429\n",
      "----------\n",
      "Train Loss:  0.3202 Acc:  0.8807\n",
      "Epoch 2529\n",
      "----------\n",
      "Train Loss:  0.3751 Acc:  0.8486\n",
      "Epoch 2629\n",
      "----------\n",
      "Train Loss:  0.1756 Acc:  0.9358\n",
      "Epoch 2729\n",
      "----------\n",
      "Train Loss:  0.2429 Acc:  0.9128\n",
      "Epoch 2829\n",
      "----------\n",
      "Train Loss:  0.4333 Acc:  0.8349\n",
      "Epoch 2929\n",
      "----------\n",
      "Train Loss:  0.3484 Acc:  0.8486\n",
      "Training complete in 7m 9s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN,\n",
    "                                 num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049\n",
      "----------\n",
      "Train Loss:  1.6838 Acc:  0.5092\n",
      "Epoch 149\n",
      "----------\n",
      "Train Loss:  0.9357 Acc:  0.5229\n",
      "Epoch 249\n",
      "----------\n",
      "Train Loss:  0.9375 Acc:  0.4679\n",
      "Epoch 349\n",
      "----------\n",
      "Train Loss:  0.7372 Acc:  0.5550\n",
      "Epoch 449\n",
      "----------\n",
      "Train Loss:  0.7356 Acc:  0.5550\n",
      "Epoch 549\n",
      "----------\n",
      "Train Loss:  0.7229 Acc:  0.5367\n",
      "Epoch 649\n",
      "----------\n",
      "Train Loss:  0.6775 Acc:  0.6009\n",
      "Epoch 749\n",
      "----------\n",
      "Train Loss:  0.6712 Acc:  0.5872\n",
      "Epoch 849\n",
      "----------\n",
      "Train Loss:  0.6403 Acc:  0.6330\n",
      "Epoch 949\n",
      "----------\n",
      "Train Loss:  0.6886 Acc:  0.6147\n",
      "Epoch 1049\n",
      "----------\n",
      "Train Loss:  0.6542 Acc:  0.5917\n",
      "Epoch 1149\n",
      "----------\n",
      "Train Loss:  0.6588 Acc:  0.6009\n",
      "Epoch 1249\n",
      "----------\n",
      "Train Loss:  0.6568 Acc:  0.6560\n",
      "Epoch 1349\n",
      "----------\n",
      "Train Loss:  0.6405 Acc:  0.5688\n",
      "Epoch 1449\n",
      "----------\n",
      "Train Loss:  0.7651 Acc:  0.5688\n",
      "Epoch 1549\n",
      "----------\n",
      "Train Loss:  0.6688 Acc:  0.5872\n",
      "Epoch 1649\n",
      "----------\n",
      "Train Loss:  0.6503 Acc:  0.6101\n",
      "Epoch 1749\n",
      "----------\n",
      "Train Loss:  0.6712 Acc:  0.6009\n",
      "Epoch 1849\n",
      "----------\n",
      "Train Loss:  0.6689 Acc:  0.6330\n",
      "Epoch 1949\n",
      "----------\n",
      "Train Loss:  0.4857 Acc:  0.8073\n",
      "Epoch 2049\n",
      "----------\n",
      "Train Loss:  0.5461 Acc:  0.7477\n",
      "Epoch 2149\n",
      "----------\n",
      "Train Loss:  0.5847 Acc:  0.6697\n",
      "Epoch 2249\n",
      "----------\n",
      "Train Loss:  0.3578 Acc:  0.8303\n",
      "Epoch 2349\n",
      "----------\n",
      "Train Loss:  0.5130 Acc:  0.7615\n",
      "Epoch 2449\n",
      "----------\n",
      "Train Loss:  0.4891 Acc:  0.7706\n",
      "Epoch 2549\n",
      "----------\n",
      "Train Loss:  0.4256 Acc:  0.8165\n",
      "Epoch 2649\n",
      "----------\n",
      "Train Loss:  0.3608 Acc:  0.8532\n",
      "Epoch 2749\n",
      "----------\n",
      "Train Loss:  0.3073 Acc:  0.8761\n",
      "Epoch 2849\n",
      "----------\n",
      "Train Loss:  0.2574 Acc:  0.9220\n",
      "Epoch 2949\n",
      "----------\n",
      "Train Loss:  0.1802 Acc:  0.9404\n",
      "Epoch 3049\n",
      "----------\n",
      "Train Loss:  0.1474 Acc:  0.9587\n",
      "Epoch 3149\n",
      "----------\n",
      "Train Loss:  0.1122 Acc:  0.9450\n",
      "Epoch 3249\n",
      "----------\n",
      "Train Loss:  0.3369 Acc:  0.8761\n",
      "Epoch 3349\n",
      "----------\n",
      "Train Loss:  0.3558 Acc:  0.8578\n",
      "Epoch 3449\n",
      "----------\n",
      "Train Loss:  0.2281 Acc:  0.8945\n",
      "Epoch 3549\n",
      "----------\n",
      "Train Loss:  0.1206 Acc:  0.9541\n",
      "Epoch 3649\n",
      "----------\n",
      "Train Loss:  0.1751 Acc:  0.9174\n",
      "Epoch 3749\n",
      "----------\n",
      "Train Loss:  0.3940 Acc:  0.8578\n",
      "Epoch 3849\n",
      "----------\n",
      "Train Loss:  0.3446 Acc:  0.8807\n",
      "Epoch 3949\n",
      "----------\n",
      "Train Loss:  0.1416 Acc:  0.9495\n",
      "Epoch 4049\n",
      "----------\n",
      "Train Loss:  0.1346 Acc:  0.9633\n",
      "Epoch 4149\n",
      "----------\n",
      "Train Loss:  0.2395 Acc:  0.9174\n",
      "Epoch 4249\n",
      "----------\n",
      "Train Loss:  0.2789 Acc:  0.9037\n",
      "Epoch 4349\n",
      "----------\n",
      "Train Loss:  0.1512 Acc:  0.9495\n",
      "Epoch 4449\n",
      "----------\n",
      "Train Loss:  0.0339 Acc:  0.9908\n",
      "Epoch 4549\n",
      "----------\n",
      "Train Loss:  0.0300 Acc:  0.9908\n",
      "Epoch 4649\n",
      "----------\n",
      "Train Loss:  0.1175 Acc:  0.9587\n",
      "Epoch 4749\n",
      "----------\n",
      "Train Loss:  0.1186 Acc:  0.9725\n",
      "Epoch 4849\n",
      "----------\n",
      "Train Loss:  0.1569 Acc:  0.9450\n",
      "Epoch 4949\n",
      "----------\n",
      "Train Loss:  0.0328 Acc:  0.9908\n",
      "Training complete in 12m 32s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN,\n",
    "                                 num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = test(resnet101_AB40_SYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5851, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StepLR (Step = 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049\n",
      "----------\n",
      "Train Loss:  1.4796 Acc:  0.4954\n",
      "Epoch 149\n",
      "----------\n",
      "Train Loss:  1.1388 Acc:  0.5459\n",
      "Epoch 249\n",
      "----------\n",
      "Train Loss:  0.8907 Acc:  0.5321\n",
      "Epoch 349\n",
      "----------\n",
      "Train Loss:  0.8053 Acc:  0.5321\n",
      "Epoch 449\n",
      "----------\n",
      "Train Loss:  0.6972 Acc:  0.5550\n",
      "Epoch 549\n",
      "----------\n",
      "Train Loss:  0.7075 Acc:  0.5917\n",
      "Epoch 649\n",
      "----------\n",
      "Train Loss:  0.7342 Acc:  0.5183\n",
      "Epoch 749\n",
      "----------\n",
      "Train Loss:  0.7090 Acc:  0.5642\n",
      "Epoch 849\n",
      "----------\n",
      "Train Loss:  0.7481 Acc:  0.5963\n",
      "Epoch 949\n",
      "----------\n",
      "Train Loss:  0.7366 Acc:  0.4908\n",
      "Epoch 1049\n",
      "----------\n",
      "Train Loss:  0.6762 Acc:  0.5734\n",
      "Epoch 1149\n",
      "----------\n",
      "Train Loss:  0.6648 Acc:  0.5642\n",
      "Epoch 1249\n",
      "----------\n",
      "Train Loss:  0.6885 Acc:  0.5917\n",
      "Epoch 1349\n",
      "----------\n",
      "Train Loss:  0.6698 Acc:  0.6009\n",
      "Epoch 1449\n",
      "----------\n",
      "Train Loss:  0.6267 Acc:  0.6697\n",
      "Epoch 1549\n",
      "----------\n",
      "Train Loss:  0.6387 Acc:  0.6101\n",
      "Epoch 1649\n",
      "----------\n",
      "Train Loss:  0.6200 Acc:  0.6606\n",
      "Epoch 1749\n",
      "----------\n",
      "Train Loss:  0.5852 Acc:  0.7064\n",
      "Epoch 1849\n",
      "----------\n",
      "Train Loss:  0.6320 Acc:  0.6651\n",
      "Epoch 1949\n",
      "----------\n",
      "Train Loss:  0.6536 Acc:  0.6789\n",
      "Epoch 2049\n",
      "----------\n",
      "Train Loss:  0.5485 Acc:  0.7294\n",
      "Epoch 2149\n",
      "----------\n",
      "Train Loss:  0.5394 Acc:  0.7661\n",
      "Epoch 2249\n",
      "----------\n",
      "Train Loss:  0.5645 Acc:  0.7385\n",
      "Epoch 2349\n",
      "----------\n",
      "Train Loss:  0.5084 Acc:  0.7752\n",
      "Epoch 2449\n",
      "----------\n",
      "Train Loss:  0.4854 Acc:  0.7752\n",
      "Epoch 2549\n",
      "----------\n",
      "Train Loss:  0.4601 Acc:  0.8073\n",
      "Epoch 2649\n",
      "----------\n",
      "Train Loss:  0.4774 Acc:  0.7752\n",
      "Epoch 2749\n",
      "----------\n",
      "Train Loss:  0.3860 Acc:  0.8440\n",
      "Epoch 2849\n",
      "----------\n",
      "Train Loss:  0.5426 Acc:  0.7523\n",
      "Epoch 2949\n",
      "----------\n",
      "Train Loss:  0.3896 Acc:  0.8578\n",
      "Epoch 3049\n",
      "----------\n",
      "Train Loss:  0.2763 Acc:  0.8945\n",
      "Epoch 3149\n",
      "----------\n",
      "Train Loss:  0.2161 Acc:  0.9083\n",
      "Epoch 3249\n",
      "----------\n",
      "Train Loss:  0.3676 Acc:  0.8624\n",
      "Epoch 3349\n",
      "----------\n",
      "Train Loss:  0.3774 Acc:  0.8257\n",
      "Epoch 3449\n",
      "----------\n",
      "Train Loss:  0.2305 Acc:  0.9128\n",
      "Epoch 3549\n",
      "----------\n",
      "Train Loss:  0.2544 Acc:  0.8945\n",
      "Epoch 3649\n",
      "----------\n",
      "Train Loss:  0.2585 Acc:  0.9083\n",
      "Epoch 3749\n",
      "----------\n",
      "Train Loss:  0.2490 Acc:  0.8945\n",
      "Epoch 3849\n",
      "----------\n",
      "Train Loss:  0.1975 Acc:  0.9128\n",
      "Epoch 3949\n",
      "----------\n",
      "Train Loss:  0.1548 Acc:  0.9495\n",
      "Epoch 4049\n",
      "----------\n",
      "Train Loss:  0.2501 Acc:  0.9037\n",
      "Epoch 4149\n",
      "----------\n",
      "Train Loss:  0.1096 Acc:  0.9633\n",
      "Epoch 4249\n",
      "----------\n",
      "Train Loss:  0.0613 Acc:  0.9771\n",
      "Epoch 4349\n",
      "----------\n",
      "Train Loss:  0.0522 Acc:  0.9771\n",
      "Epoch 4449\n",
      "----------\n",
      "Train Loss:  0.1505 Acc:  0.9587\n",
      "Epoch 4549\n",
      "----------\n",
      "Train Loss:  0.0640 Acc:  0.9725\n",
      "Epoch 4649\n",
      "----------\n",
      "Train Loss:  0.0579 Acc:  0.9679\n",
      "Epoch 4749\n",
      "----------\n",
      "Train Loss:  0.0990 Acc:  0.9679\n",
      "Epoch 4849\n",
      "----------\n",
      "Train Loss:  0.0705 Acc:  0.9679\n",
      "Epoch 4949\n",
      "----------\n",
      "Train Loss:  0.2134 Acc:  0.9312\n",
      "Training complete in 13m 2s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer_AB40_SYN,\n",
    "                                step_size=10, gamma=0.8)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN, scheduler,\n",
    "                                 num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,acc_test = test(resnet101_AB40_SYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5957, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,acc_train = test(resnet101_AB40_SYN,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9541, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StepLR (Step=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049\n",
      "----------\n",
      "Train Loss:  1.2672 Acc:  0.5505\n",
      "Epoch 149\n",
      "----------\n",
      "Train Loss:  1.1822 Acc:  0.5000\n",
      "Epoch 249\n",
      "----------\n",
      "Train Loss:  1.4839 Acc:  0.4771\n",
      "Epoch 349\n",
      "----------\n",
      "Train Loss:  0.9365 Acc:  0.4633\n",
      "Epoch 449\n",
      "----------\n",
      "Train Loss:  0.7102 Acc:  0.5596\n",
      "Epoch 549\n",
      "----------\n",
      "Train Loss:  0.7386 Acc:  0.5229\n",
      "Epoch 649\n",
      "----------\n",
      "Train Loss:  0.7082 Acc:  0.5229\n",
      "Epoch 749\n",
      "----------\n",
      "Train Loss:  0.6792 Acc:  0.5734\n",
      "Epoch 849\n",
      "----------\n",
      "Train Loss:  0.7136 Acc:  0.5688\n",
      "Epoch 949\n",
      "----------\n",
      "Train Loss:  0.6581 Acc:  0.5780\n",
      "Epoch 1049\n",
      "----------\n",
      "Train Loss:  0.6623 Acc:  0.6009\n",
      "Epoch 1149\n",
      "----------\n",
      "Train Loss:  0.6495 Acc:  0.6239\n",
      "Epoch 1249\n",
      "----------\n",
      "Train Loss:  0.6373 Acc:  0.6193\n",
      "Epoch 1349\n",
      "----------\n",
      "Train Loss:  0.7053 Acc:  0.5642\n",
      "Epoch 1449\n",
      "----------\n",
      "Train Loss:  0.6294 Acc:  0.6239\n",
      "Epoch 1549\n",
      "----------\n",
      "Train Loss:  0.5254 Acc:  0.7615\n",
      "Epoch 1649\n",
      "----------\n",
      "Train Loss:  0.4941 Acc:  0.7339\n",
      "Epoch 1749\n",
      "----------\n",
      "Train Loss:  0.5976 Acc:  0.6881\n",
      "Epoch 1849\n",
      "----------\n",
      "Train Loss:  0.6546 Acc:  0.5963\n",
      "Epoch 1949\n",
      "----------\n",
      "Train Loss:  0.5857 Acc:  0.6560\n",
      "Epoch 2049\n",
      "----------\n",
      "Train Loss:  0.6084 Acc:  0.6560\n",
      "Epoch 2149\n",
      "----------\n",
      "Train Loss:  0.4954 Acc:  0.7477\n",
      "Epoch 2249\n",
      "----------\n",
      "Train Loss:  0.4420 Acc:  0.8119\n",
      "Epoch 2349\n",
      "----------\n",
      "Train Loss:  0.4058 Acc:  0.8165\n",
      "Epoch 2449\n",
      "----------\n",
      "Train Loss:  0.4889 Acc:  0.7661\n",
      "Epoch 2549\n",
      "----------\n",
      "Train Loss:  0.3831 Acc:  0.7982\n",
      "Epoch 2649\n",
      "----------\n",
      "Train Loss:  0.3319 Acc:  0.8532\n",
      "Epoch 2749\n",
      "----------\n",
      "Train Loss:  0.2113 Acc:  0.9128\n",
      "Epoch 2849\n",
      "----------\n",
      "Train Loss:  0.2505 Acc:  0.8899\n",
      "Epoch 2949\n",
      "----------\n",
      "Train Loss:  0.3814 Acc:  0.8349\n",
      "Epoch 3049\n",
      "----------\n",
      "Train Loss:  0.2287 Acc:  0.9220\n",
      "Epoch 3149\n",
      "----------\n",
      "Train Loss:  0.1369 Acc:  0.9541\n",
      "Epoch 3249\n",
      "----------\n",
      "Train Loss:  0.1153 Acc:  0.9587\n",
      "Epoch 3349\n",
      "----------\n",
      "Train Loss:  0.1498 Acc:  0.9358\n",
      "Epoch 3449\n",
      "----------\n",
      "Train Loss:  0.0882 Acc:  0.9633\n",
      "Epoch 3549\n",
      "----------\n",
      "Train Loss:  0.0511 Acc:  0.9725\n",
      "Epoch 3649\n",
      "----------\n",
      "Train Loss:  0.0330 Acc:  0.9954\n",
      "Epoch 3749\n",
      "----------\n",
      "Train Loss:  0.0528 Acc:  0.9771\n",
      "Epoch 3849\n",
      "----------\n",
      "Train Loss:  0.0869 Acc:  0.9679\n",
      "Epoch 3949\n",
      "----------\n",
      "Train Loss:  0.0345 Acc:  0.9954\n",
      "Epoch 4049\n",
      "----------\n",
      "Train Loss:  0.0296 Acc:  0.9954\n",
      "Epoch 4149\n",
      "----------\n",
      "Train Loss:  0.1236 Acc:  0.9541\n",
      "Epoch 4249\n",
      "----------\n",
      "Train Loss:  0.0443 Acc:  0.9908\n",
      "Epoch 4349\n",
      "----------\n",
      "Train Loss:  0.0770 Acc:  0.9771\n",
      "Epoch 4449\n",
      "----------\n",
      "Train Loss:  0.1262 Acc:  0.9587\n",
      "Epoch 4549\n",
      "----------\n",
      "Train Loss:  0.0602 Acc:  0.9725\n",
      "Epoch 4649\n",
      "----------\n",
      "Train Loss:  0.0454 Acc:  0.9817\n",
      "Epoch 4749\n",
      "----------\n",
      "Train Loss:  0.0062 Acc:  1.0000\n",
      "Epoch 4849\n",
      "----------\n",
      "Train Loss:  0.0412 Acc:  0.9862\n",
      "Epoch 4949\n",
      "----------\n",
      "Train Loss:  0.0270 Acc:  0.9862\n",
      "Training complete in 12m 59s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer_AB40_SYN,\n",
    "                                step_size=5, gamma=0.8)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN, scheduler,\n",
    "                                 num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7660, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_test_5 = test(resnet101_AB40_SYN)\n",
    "acc_test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7660, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_test_6 = test(model_AB40_SYN)\n",
    "acc_test_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_train_5 = test(resnet101_AB40_SYN, train_loader)\n",
    "acc_train_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_train_6 = test(model_AB40_SYN,train_loader)\n",
    "acc_train_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(scheduler.last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  StepLR (step size=5) with l2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049\n",
      "----------\n",
      "Train Loss:  1.0532 Acc:  0.5321\n",
      "Epoch 149\n",
      "----------\n",
      "Train Loss:  0.8473 Acc:  0.5413\n",
      "Epoch 249\n",
      "----------\n",
      "Train Loss:  0.8572 Acc:  0.5229\n",
      "Epoch 349\n",
      "----------\n",
      "Train Loss:  0.8427 Acc:  0.4908\n",
      "Epoch 449\n",
      "----------\n",
      "Train Loss:  0.8567 Acc:  0.5000\n",
      "Epoch 549\n",
      "----------\n",
      "Train Loss:  0.7037 Acc:  0.5550\n",
      "Epoch 649\n",
      "----------\n",
      "Train Loss:  0.6694 Acc:  0.6147\n",
      "Epoch 749\n",
      "----------\n",
      "Train Loss:  0.6595 Acc:  0.5596\n",
      "Epoch 849\n",
      "----------\n",
      "Train Loss:  0.6402 Acc:  0.6376\n",
      "Epoch 949\n",
      "----------\n",
      "Train Loss:  0.6334 Acc:  0.5917\n",
      "Epoch 1049\n",
      "----------\n",
      "Train Loss:  0.6613 Acc:  0.6193\n",
      "Epoch 1149\n",
      "----------\n",
      "Train Loss:  0.6117 Acc:  0.6697\n",
      "Epoch 1249\n",
      "----------\n",
      "Train Loss:  0.6250 Acc:  0.6376\n",
      "Epoch 1349\n",
      "----------\n",
      "Train Loss:  0.5830 Acc:  0.6697\n",
      "Epoch 1449\n",
      "----------\n",
      "Train Loss:  0.5315 Acc:  0.7385\n",
      "Epoch 1549\n",
      "----------\n",
      "Train Loss:  0.3709 Acc:  0.8165\n",
      "Epoch 1649\n",
      "----------\n",
      "Train Loss:  0.3944 Acc:  0.8303\n",
      "Epoch 1749\n",
      "----------\n",
      "Train Loss:  0.4937 Acc:  0.8028\n",
      "Epoch 1849\n",
      "----------\n",
      "Train Loss:  0.3068 Acc:  0.8716\n",
      "Epoch 1949\n",
      "----------\n",
      "Train Loss:  0.4268 Acc:  0.8394\n",
      "Epoch 2049\n",
      "----------\n",
      "Train Loss:  0.5466 Acc:  0.7110\n",
      "Epoch 2149\n",
      "----------\n",
      "Train Loss:  0.3026 Acc:  0.9220\n",
      "Epoch 2249\n",
      "----------\n",
      "Train Loss:  0.1876 Acc:  0.9358\n",
      "Epoch 2349\n",
      "----------\n",
      "Train Loss:  0.1697 Acc:  0.9404\n",
      "Epoch 2449\n",
      "----------\n",
      "Train Loss:  0.3253 Acc:  0.8807\n",
      "Epoch 2549\n",
      "----------\n",
      "Train Loss:  0.3010 Acc:  0.8624\n",
      "Epoch 2649\n",
      "----------\n",
      "Train Loss:  0.1633 Acc:  0.9541\n",
      "Epoch 2749\n",
      "----------\n",
      "Train Loss:  0.1395 Acc:  0.9633\n",
      "Epoch 2849\n",
      "----------\n",
      "Train Loss:  0.2302 Acc:  0.9174\n",
      "Epoch 2949\n",
      "----------\n",
      "Train Loss:  0.1971 Acc:  0.9174\n",
      "Epoch 3049\n",
      "----------\n",
      "Train Loss:  0.1858 Acc:  0.9266\n",
      "Epoch 3149\n",
      "----------\n",
      "Train Loss:  0.0700 Acc:  0.9771\n",
      "Epoch 3249\n",
      "----------\n",
      "Train Loss:  0.1046 Acc:  0.9450\n",
      "Epoch 3349\n",
      "----------\n",
      "Train Loss:  0.1141 Acc:  0.9541\n",
      "Epoch 3449\n",
      "----------\n",
      "Train Loss:  0.1186 Acc:  0.9541\n",
      "Epoch 3549\n",
      "----------\n",
      "Train Loss:  0.0830 Acc:  0.9633\n",
      "Epoch 3649\n",
      "----------\n",
      "Train Loss:  0.0330 Acc:  0.9954\n",
      "Epoch 3749\n",
      "----------\n",
      "Train Loss:  0.0250 Acc:  0.9954\n",
      "Epoch 3849\n",
      "----------\n",
      "Train Loss:  0.0159 Acc:  0.9954\n",
      "Epoch 3949\n",
      "----------\n",
      "Train Loss:  0.0250 Acc:  0.9908\n",
      "Epoch 4049\n",
      "----------\n",
      "Train Loss:  0.0386 Acc:  0.9862\n",
      "Epoch 4149\n",
      "----------\n",
      "Train Loss:  0.0148 Acc:  1.0000\n",
      "Epoch 4249\n",
      "----------\n",
      "Train Loss:  0.0140 Acc:  1.0000\n",
      "Epoch 4349\n",
      "----------\n",
      "Train Loss:  0.0079 Acc:  1.0000\n",
      "Epoch 4449\n",
      "----------\n",
      "Train Loss:  0.0112 Acc:  1.0000\n",
      "Epoch 4549\n",
      "----------\n",
      "Train Loss:  0.0094 Acc:  1.0000\n",
      "Epoch 4649\n",
      "----------\n",
      "Train Loss:  0.0054 Acc:  1.0000\n",
      "Epoch 4749\n",
      "----------\n",
      "Train Loss:  0.0043 Acc:  1.0000\n",
      "Epoch 4849\n",
      "----------\n",
      "Train Loss:  0.0082 Acc:  1.0000\n",
      "Epoch 4949\n",
      "----------\n",
      "Train Loss:  0.0088 Acc:  1.0000\n",
      "Training complete in 14m 3s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9, weight_decay=0.01)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer_AB40_SYN,\n",
    "                                step_size=5, gamma=0.8)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN, scheduler,\n",
    "                                 num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7021, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_test_1 = test(resnet101_AB40_SYN)\n",
    "acc_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_train_1 = test(resnet101_AB40_SYN,train_loader)\n",
    "acc_train_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049\n",
      "----------\n",
      "Train Loss:  1.3814 Acc:  0.5138\n",
      "Epoch 149\n",
      "----------\n",
      "Train Loss:  1.1416 Acc:  0.5046\n",
      "Epoch 249\n",
      "----------\n",
      "Train Loss:  0.7246 Acc:  0.4862\n",
      "Epoch 349\n",
      "----------\n",
      "Train Loss:  0.7150 Acc:  0.4725\n",
      "Epoch 449\n",
      "----------\n",
      "Train Loss:  0.7058 Acc:  0.5092\n",
      "Epoch 549\n",
      "----------\n",
      "Train Loss:  0.6984 Acc:  0.4908\n",
      "Epoch 649\n",
      "----------\n",
      "Train Loss:  0.6988 Acc:  0.5138\n",
      "Epoch 749\n",
      "----------\n",
      "Train Loss:  0.6960 Acc:  0.4495\n",
      "Epoch 849\n",
      "----------\n",
      "Train Loss:  0.6940 Acc:  0.4587\n",
      "Epoch 949\n",
      "----------\n",
      "Train Loss:  0.6943 Acc:  0.4954\n",
      "Epoch 1049\n",
      "----------\n",
      "Train Loss:  0.6935 Acc:  0.5092\n",
      "Epoch 1149\n",
      "----------\n",
      "Train Loss:  0.6939 Acc:  0.5092\n",
      "Epoch 1249\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 1349\n",
      "----------\n",
      "Train Loss:  0.6937 Acc:  0.5092\n",
      "Epoch 1449\n",
      "----------\n",
      "Train Loss:  0.6936 Acc:  0.5092\n",
      "Epoch 1549\n",
      "----------\n",
      "Train Loss:  0.6936 Acc:  0.5092\n",
      "Epoch 1649\n",
      "----------\n",
      "Train Loss:  0.6934 Acc:  0.5092\n",
      "Epoch 1749\n",
      "----------\n",
      "Train Loss:  0.6940 Acc:  0.5092\n",
      "Epoch 1849\n",
      "----------\n",
      "Train Loss:  0.6935 Acc:  0.5092\n",
      "Epoch 1949\n",
      "----------\n",
      "Train Loss:  0.6941 Acc:  0.5092\n",
      "Epoch 2049\n",
      "----------\n",
      "Train Loss:  0.6935 Acc:  0.5092\n",
      "Epoch 2149\n",
      "----------\n",
      "Train Loss:  0.6933 Acc:  0.5092\n",
      "Epoch 2249\n",
      "----------\n",
      "Train Loss:  0.6944 Acc:  0.5092\n",
      "Epoch 2349\n",
      "----------\n",
      "Train Loss:  0.6933 Acc:  0.5092\n",
      "Epoch 2449\n",
      "----------\n",
      "Train Loss:  0.6935 Acc:  0.4908\n",
      "Epoch 2549\n",
      "----------\n",
      "Train Loss:  0.6947 Acc:  0.5092\n",
      "Epoch 2649\n",
      "----------\n",
      "Train Loss:  0.6933 Acc:  0.5092\n",
      "Epoch 2749\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 2849\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 2949\n",
      "----------\n",
      "Train Loss:  0.6933 Acc:  0.5092\n",
      "Epoch 3049\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 3149\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 3249\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 3349\n",
      "----------\n",
      "Train Loss:  0.6936 Acc:  0.5092\n",
      "Epoch 3449\n",
      "----------\n",
      "Train Loss:  0.6933 Acc:  0.5092\n",
      "Epoch 3549\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 3649\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 3749\n",
      "----------\n",
      "Train Loss:  0.6933 Acc:  0.5092\n",
      "Epoch 3849\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 3949\n",
      "----------\n",
      "Train Loss:  0.6934 Acc:  0.5092\n",
      "Epoch 4049\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 4149\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 4249\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 4349\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 4449\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 4549\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 4649\n",
      "----------\n",
      "Train Loss:  0.6932 Acc:  0.5092\n",
      "Epoch 4749\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 4849\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Epoch 4949\n",
      "----------\n",
      "Train Loss:  0.6931 Acc:  0.5092\n",
      "Training complete in 14m 8s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9, weight_decay=0.1)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer_AB40_SYN,\n",
    "                                step_size=5, gamma=0.8)\n",
    "\n",
    "resnet101_AB40_SYN = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN, scheduler,\n",
    "                                 num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5106, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_test_2 = test(resnet101_AB40_SYN)\n",
    "acc_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5092, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc_train_2 = test(resnet101_AB40_SYN,train_loader)\n",
    "acc_train_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 = 0.05 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049\n",
      "----------\n",
      "Train Loss:  1.3130 Acc:  0.5046\n",
      "Epoch 149\n",
      "----------\n",
      "Train Loss:  1.1142 Acc:  0.4633\n",
      "Epoch 249\n",
      "----------\n",
      "Train Loss:  1.0775 Acc:  0.5138\n",
      "Epoch 349\n",
      "----------\n",
      "Train Loss:  0.7925 Acc:  0.4771\n",
      "Epoch 449\n",
      "----------\n",
      "Train Loss:  0.7335 Acc:  0.4725\n",
      "Epoch 549\n",
      "----------\n",
      "Train Loss:  0.6897 Acc:  0.5413\n",
      "Epoch 649\n",
      "----------\n",
      "Train Loss:  0.7016 Acc:  0.4862\n",
      "Epoch 749\n",
      "----------\n",
      "Train Loss:  0.6909 Acc:  0.5000\n",
      "Epoch 849\n",
      "----------\n",
      "Train Loss:  0.6855 Acc:  0.5321\n",
      "Epoch 949\n",
      "----------\n",
      "Train Loss:  0.6800 Acc:  0.5826\n",
      "Epoch 1049\n",
      "----------\n",
      "Train Loss:  0.6930 Acc:  0.4908\n",
      "Epoch 1149\n",
      "----------\n",
      "Train Loss:  0.6570 Acc:  0.5780\n",
      "Epoch 1249\n",
      "----------\n",
      "Train Loss:  0.6658 Acc:  0.5505\n",
      "Epoch 1349\n",
      "----------\n",
      "Train Loss:  0.6851 Acc:  0.5688\n",
      "Epoch 1449\n",
      "----------\n",
      "Train Loss:  0.6782 Acc:  0.5688\n",
      "Epoch 1549\n",
      "----------\n",
      "Train Loss:  0.6653 Acc:  0.5826\n",
      "Epoch 1649\n",
      "----------\n",
      "Train Loss:  0.6455 Acc:  0.6330\n",
      "Epoch 1749\n",
      "----------\n",
      "Train Loss:  0.6264 Acc:  0.6284\n",
      "Epoch 1849\n",
      "----------\n",
      "Train Loss:  0.6635 Acc:  0.5963\n",
      "Epoch 1949\n",
      "----------\n",
      "Train Loss:  0.6897 Acc:  0.5000\n",
      "Epoch 2049\n",
      "----------\n",
      "Train Loss:  0.6652 Acc:  0.5963\n",
      "Epoch 2149\n",
      "----------\n",
      "Train Loss:  0.6578 Acc:  0.6193\n",
      "Epoch 2249\n",
      "----------\n",
      "Train Loss:  0.6480 Acc:  0.6055\n",
      "Epoch 2349\n",
      "----------\n",
      "Train Loss:  0.6507 Acc:  0.6468\n",
      "Epoch 2449\n",
      "----------\n",
      "Train Loss:  0.6013 Acc:  0.6927\n",
      "Epoch 2549\n",
      "----------\n",
      "Train Loss:  0.6256 Acc:  0.6697\n",
      "Epoch 2649\n",
      "----------\n",
      "Train Loss:  0.5906 Acc:  0.7064\n",
      "Epoch 2749\n",
      "----------\n",
      "Train Loss:  0.5629 Acc:  0.7339\n",
      "Epoch 2849\n",
      "----------\n",
      "Train Loss:  0.6114 Acc:  0.6835\n",
      "Epoch 2949\n",
      "----------\n",
      "Train Loss:  0.5698 Acc:  0.6972\n",
      "Epoch 3049\n",
      "----------\n",
      "Train Loss:  0.5263 Acc:  0.7385\n",
      "Epoch 3149\n",
      "----------\n",
      "Train Loss:  0.5321 Acc:  0.7569\n",
      "Epoch 3249\n",
      "----------\n",
      "Train Loss:  0.5189 Acc:  0.7523\n",
      "Epoch 3349\n",
      "----------\n",
      "Train Loss:  0.5224 Acc:  0.7615\n",
      "Epoch 3449\n",
      "----------\n",
      "Train Loss:  0.5172 Acc:  0.7661\n",
      "Epoch 3549\n",
      "----------\n",
      "Train Loss:  0.4586 Acc:  0.8028\n",
      "Epoch 3649\n",
      "----------\n",
      "Train Loss:  0.4185 Acc:  0.8440\n",
      "Epoch 3749\n",
      "----------\n",
      "Train Loss:  0.3806 Acc:  0.8853\n",
      "Epoch 3849\n",
      "----------\n",
      "Train Loss:  0.3716 Acc:  0.8761\n",
      "Epoch 3949\n",
      "----------\n",
      "Train Loss:  0.3542 Acc:  0.8624\n",
      "Epoch 4049\n",
      "----------\n",
      "Train Loss:  0.3585 Acc:  0.8716\n",
      "Epoch 4149\n",
      "----------\n",
      "Train Loss:  0.3095 Acc:  0.9037\n",
      "Epoch 4249\n",
      "----------\n",
      "Train Loss:  0.2655 Acc:  0.9404\n",
      "Epoch 4349\n",
      "----------\n",
      "Train Loss:  0.3005 Acc:  0.8899\n",
      "Epoch 4449\n",
      "----------\n",
      "Train Loss:  0.3349 Acc:  0.8670\n",
      "Epoch 4549\n",
      "----------\n",
      "Train Loss:  0.2355 Acc:  0.9312\n",
      "Epoch 4649\n",
      "----------\n",
      "Train Loss:  0.1981 Acc:  0.9725\n",
      "Epoch 4749\n",
      "----------\n",
      "Train Loss:  0.1667 Acc:  0.9771\n",
      "Epoch 4849\n",
      "----------\n",
      "Train Loss:  0.1714 Acc:  0.9679\n",
      "Epoch 4949\n",
      "----------\n",
      "Train Loss:  0.1342 Acc:  0.9908\n",
      "Training complete in 13m 49s\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_AB40_SYN = resnet101(pretrained=True)\n",
    "# The size of each output sample is set to 2\n",
    "num_in_ft = model_AB40_SYN.fc.in_features\n",
    "model_AB40_SYN.fc = nn.Linear(num_in_ft, 2)\n",
    "model_AB40_SYN.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_AB40_SYN = torch.optim.SGD(model_AB40_SYN.parameters(),\n",
    "                                     lr=0.01, momentum=0.9, weight_decay=0.05)\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer_AB40_SYN,\n",
    "                                step_size=5, gamma=0.8)\n",
    "\n",
    "resnet101_AB40_SYN_1 = train_model(model_AB40_SYN, criterion,\n",
    "                                 optimizer_AB40_SYN, scheduler,\n",
    "                                 num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,acc_train_3 = test(resnet101_AB40_SYN_1,train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9312, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4787, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,acc_test_3 = test(resnet101_AB40_SYN_1)\n",
    "acc_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4787, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,acc_test_3 = test(model_AB40_SYN)\n",
    "acc_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet101_AB40_SYN_1.named_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StepLR with Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
